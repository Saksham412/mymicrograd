# Save the updated README content as a markdown file
readme_content = """
# MicroGrad - A Simple Autograd Engine

**MicroGrad** is a basic automatic differentiation library built from scratch in Python. It helps in understanding how gradients are computed in neural networks.

## Features

- Computes gradients using backpropagation.
- Builds a computational graph dynamically.
- Easy to modify and experiment with.

## Setup

### Requirements

- Python 3.10+
- Jupyter Notebook

### Run the Notebook

```bash
git clone <repository_url>
cd micrograd
jupyter notebook mymicrograd.ipynb
